# ì¼íšŒì„± ì½”ë“œ -> ì£¼ì„ í•´ì œí•˜ì§€ ë§ˆì„¸ìš”.
'''
# ì¼íšŒì„± ì½”ë“œ -> ì£¼ì„ í•´ì œí•˜ì§€ ë§ˆì„¸ìš”.
import os
import faiss
from sentence_transformers import SentenceTransformer
import pandas as pd
import numpy as np
import pickle

# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv('../data/jobkorea.csv')

# wide í˜•íƒœë¥¼ tidy í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def data_preprocess():
    qa_pairs = []
    for idx, row in df.iterrows():
        for i in range(1, 20):  # question1 ~ question19ê¹Œì§€
            q_col = f'question{i}'
            a_col = f'answer{i}'
            if pd.notna(row.get(q_col)) and pd.notna(row.get(a_col)):
                qa_pairs.append({
                    'question': row[q_col],
                    'answer': row[a_col]
                })
    return pd.DataFrame(qa_pairs)

def main():
    # 1. ë°ì´í„° ì „ì²˜ë¦¬
    qa_df = data_preprocess()

    # 2. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
    model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')

    # 3. ì§ˆë¬¸ ì„ë² ë”©
    questions = qa_df['question'].tolist()
    question_embeddings = model.encode(questions, show_progress_bar=True)

    # 4. FAISS ì¸ë±ìŠ¤ ìƒì„± (cosine similarityë¥¼ ìœ„í•œ L2 normalize)
    dimension = question_embeddings.shape[1]
    index = faiss.IndexFlatL2(dimension)  # cosine similarity = L2 on normalized vectors
    faiss.normalize_L2(question_embeddings)
    index.add(np.array(question_embeddings))

    # 5. ì¸ë±ìŠ¤ì™€ ë§¤í•‘ ì •ë³´ë¥¼ ì €ì¥
    faiss.write_index(index, "../faiss_index.jobkorea")  # ë²¡í„° ì¸ë±ìŠ¤ -> ì¸ë±ìŠ¤ë¡œ ì•„ë˜ ì§ˆë¬¸/ë‹µë³€ì´ë‘ ì—°ê²°ì§€ì–´ì•¼í•¨
    with open("../faiss_qa_mapping.pkl", "wb") as f:  # ì§ˆë¬¸/ë‹µë³€ ë§¤í•‘ ì •ë³´
        pickle.dump(qa_df.to_dict(orient='records'), f)

    print("âœ… ì„ë² ë”© ë° FAISS ì¸ë±ì‹± ì™„ë£Œ!")

# ğŸ”¥ ì‹¤í–‰ íŠ¸ë¦¬ê±°
if __name__ == "__main__":
    main()
'''