import os
import pandas as pd
from PyPDF2 import PdfReader
import openai
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain_community.llms import OpenAI
from routers.pdf_storage import pdf_storage
from config import FILE_DIR, API_KEY
from db import SessionLocal, MainQuestionDB, FollowUpDB, InterviewSessionDB  # DB ëª¨ë¸ ì„í¬íŠ¸

class InterviewSession:
    def __init__(self, token: str, question_num=5, answer_per_question=5, mock_data_path=None):
        self.token = token
        self.current_main = 0
        self.current_follow_up = 0
        self.current_answer = 0

        self.question_num = question_num
        self.answer_per_question = answer_per_question
        self.main_questions = []
        self.follow_up_questions = [[] for _ in range(question_num)]
        self.answers = [[] for _ in range(question_num)]
        self.hints = [[] for _ in range(question_num)]  # ì„¸ì…˜ ë‚´ ìœ ì§€ (DB ì €ì¥ X)
        self.feedbacks = [[] for _ in range(question_num)]  # ì„¸ì…˜ ë‚´ ìœ ì§€ (DB ì €ì¥ X)

        self.llm = OpenAI(api_key=API_KEY)

        # âœ… PDF í…ìŠ¤íŠ¸ & ì±„ìš© URL ì§ì ‘ ê°€ì ¸ì˜¤ê¸° (íŒŒì¼ ë³€í™˜ X)
        pdf_data = pdf_storage.get_pdf(token)
        if not pdf_data:
            raise ValueError(f"ğŸš¨ í•´ë‹¹ í† í°({token})ì— ëŒ€í•œ PDF íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        self.resume = pdf_data.get("resume_text", "ğŸš¨ ì´ë ¥ì„œ í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        self.recruit_url = pdf_data.get("recruitUrl", "ğŸš¨ ì±„ìš© ê³µê³  URLì´ ì—†ìŠµë‹ˆë‹¤.")

        self.mock_data_path = mock_data_path
        self.example_questions = self._load_mock_interview_data(mock_data_path)

    def get_current_state(self):
        return {
            "total_main": len(self.main_questions),
            "current_main": self.current_main,
            "current_follow_up": self.current_follow_up,
            "current_answer": self.current_answer,
            "remaining_answer": self.answer_per_question - self.current_answer,
        }

    def _load_mock_interview_data(self, mock_data_path=None):
        """ëª¨ì˜ ë©´ì ‘ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” ë©”ì„œë“œ"""
        if not mock_data_path:
            mock_data_path = os.path.join(FILE_DIR, "mock_interview_data.json")
        
        try:
            if os.path.exists(mock_data_path):
                df = pd.read_json(mock_data_path)
                return "\n".join(df['question'].tolist()[:5])  # ìƒìœ„ 5ê°œ ì§ˆë¬¸ë§Œ ì‚¬ìš©
            else:
                return """
                ì§ˆë¬¸: í”„ë¡œì íŠ¸ì—ì„œ ê°€ì¥ í° ë„ì „ ê³¼ì œëŠ” ë¬´ì—‡ì´ì—ˆë‚˜ìš”?
                ì§ˆë¬¸: íŒ€ í”„ë¡œì íŠ¸ì—ì„œ ê°ˆë“±ì´ ë°œìƒí–ˆì„ ë•Œ ì–´ë–»ê²Œ í•´ê²°í•˜ì…¨ë‚˜ìš”?
                ì§ˆë¬¸: ê¸°ìˆ  ìŠ¤íƒì„ ì„ íƒí•œ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?
                ì§ˆë¬¸: í”„ë¡œì íŠ¸ì—ì„œ ë³¸ì¸ì˜ ì—­í• ì€ ë¬´ì—‡ì´ì—ˆë‚˜ìš”?
                ì§ˆë¬¸: ê°€ì¥ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œí•œ í”„ë¡œì íŠ¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?
                """
        except Exception as e:
            print(f"ëª¨ì˜ ë©´ì ‘ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {str(e)}")
            return ""

    async def generate_main_questions(self, num_questions: int = 5):
        """ì—¬ëŸ¬ ê°œì˜ ëŒ€í‘œ ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ë©”ì„œë“œ"""
        try:
            questions = []
            for i in range(num_questions):
                print(f"ğŸ“ {i+1}ë²ˆì§¸ ì§ˆë¬¸ ìƒì„± ì‹œë„ ì¤‘...")
                question = await self.generate_main_question()
                if question:
                    questions.append(question)
                    print(f"âœ… {i+1}ë²ˆì§¸ ì§ˆë¬¸ ìƒì„± ì„±ê³µ")
                else:
                    print(f"âŒ {i+1}ë²ˆì§¸ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨")
                    break
            
            if not questions:
                print("âŒ ìƒì„±ëœ ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                return ["ëŒ€í‘œì§ˆë¬¸ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."] * num_questions
            
            return questions
        except Exception as e:
            print(f"âŒ ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return ["ëŒ€í‘œì§ˆë¬¸ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."] * num_questions

    async def generate_main_question(self):
        try:
            if len(self.main_questions) >= self.question_num:
                print("âŒ ìµœëŒ€ ì§ˆë¬¸ ìˆ˜ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.")
                return None
            
            print("ğŸ“ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")
            prompt = PromptTemplate(
                template=self._get_question_template(),
                input_variables=['resume', 'job_url']
            )
            chain = LLMChain(prompt=prompt, llm=self.llm)

            # ìµœëŒ€ 3ë²ˆê¹Œì§€ ì‹œë„
            max_attempts = 3
            for attempt in range(max_attempts):
                print(f"ğŸ¤– OpenAI API í˜¸ì¶œ ì¤‘... (ì‹œë„ {attempt + 1}/{max_attempts})")
                question = chain.run({
                    'resume': self.resume,
                    'job_url': self.recruit_url
                })
                print(f"ğŸ“„ API ì‘ë‹µ: {question}")
                
                # ì§ˆë¬¸ í˜•ì‹ ê²€ì¦ ë° ì •ì œ
                if not question:
                    print("âŒ ì§ˆë¬¸ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    continue
                
                # "ì§ˆë¬¸:" ë¶€ë¶„ ì œê±°í•˜ê³  ì‹¤ì œ ì§ˆë¬¸ë§Œ ì¶”ì¶œ
                question = question.strip()
                if "ì§ˆë¬¸:" in question:
                    question = question.split("ì§ˆë¬¸:")[1].strip()
                    print(f"âœ… ì§ˆë¬¸ ì¶”ì¶œ ì™„ë£Œ: {question}")
                else:
                    print("âš ï¸ 'ì§ˆë¬¸:' í˜•ì‹ì´ ì—†ìŠµë‹ˆë‹¤.")
                    continue
                
                if not question:
                    print("âŒ ì§ˆë¬¸ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                    continue

                # ì¤‘ë³µ ì²´í¬
                is_duplicate = False
                for existing_question in self.main_questions:
                    # ìœ ì‚¬ë„ ì²´í¬ (ë‹¨ìˆœ ë¬¸ìì—´ í¬í•¨ ì—¬ë¶€)
                    if question in existing_question or existing_question in question:
                        print(f"âš ï¸ ì¤‘ë³µëœ ì§ˆë¬¸ ê°ì§€: {question}")
                        is_duplicate = True
                        break
                
                if is_duplicate:
                    continue

                # DBì— ì €ì¥
                print("ğŸ’¾ DB ì €ì¥ ì‹œë„ ì¤‘...")
                db = SessionLocal()
                try:
                    # ì„¸ì…˜ IDë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ InterviewSessionDB ì¡°íšŒ
                    session = db.query(InterviewSessionDB).filter_by(session_token=self.token).first()
                    if not session:
                        print(f"âŒ ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.token}")
                        continue
                    
                    new_question = MainQuestionDB(
                        session_id=session.id,  # ì„¸ì…˜ ID ì‚¬ìš©
                        content=question
                    )
                    db.add(new_question)
                    db.commit()
                    db.refresh(new_question)
                    
                    # ë©”ëª¨ë¦¬ì— ì§ˆë¬¸ ì¶”ê°€
                    self.main_questions.append(question)
                    print(f"âœ… ì§ˆë¬¸ ìƒì„± ì„±ê³µ: {question}")
                    
                    return question
                    
                except Exception as db_error:
                    print(f"âŒ DB ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(db_error)}")
                    db.rollback()
                    continue
                finally:
                    db.close()
            
            print("âŒ ìœ íš¨í•œ ì§ˆë¬¸ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return None
            
        except Exception as e:
            print(f"âŒ ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None

    async def generate_follow_up(self, last_answer: str):
        try:
            if len(self.follow_up_questions[self.current_main]) >= self.answer_per_question - 1:
                return None
            
            prompt = PromptTemplate(template=self._get_follow_up_template(), input_variables=['answer'])
            chain = LLMChain(prompt=prompt, llm=self.llm)

            # ë¹„ë™ê¸° í˜¸ì¶œì„ ë™ê¸° í˜¸ì¶œë¡œ ë³€ê²½
            question = chain.run({'answer': last_answer})
            question = question.strip() if question else "ê¼¬ë¦¬ì§ˆë¬¸ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

            # **DBì— ì €ì¥**
            db = SessionLocal()
            try:
                new_follow_up = FollowUpDB(main_question_id=self.current_main, content=question)
                db.add(new_follow_up)
                db.commit()
                db.refresh(new_follow_up)
                self.follow_up_questions[self.current_main].append(question)
            finally:
                db.close()

            return question
        except Exception as e:
            print(f"ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return "ê¼¬ë¦¬ì§ˆë¬¸ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    def store_user_answer(self, question_id: int, answer: str):
        """ì‚¬ìš©ìì˜ ë‹µë³€ì„ DBì— ì €ì¥"""
        db = SessionLocal()
        try:
            follow_up = db.query(FollowUpDB).filter(FollowUpDB.id == question_id).first()
            if follow_up:
                follow_up.answer = answer
                db.commit()
                db.refresh(follow_up)
                self.answers[self.current_main].append(answer)
        finally:
            db.close()

    async def generate_hint(self, last_question):
        try:
            prompt = PromptTemplate(template=self._get_hint_template(), input_variables=['question'])
            chain = LLMChain(prompt=prompt, llm=self.llm)
            # ë¹„ë™ê¸° í˜¸ì¶œì„ ë™ê¸° í˜¸ì¶œë¡œ ë³€ê²½
            hint = chain.run({'question': last_question})
            hint = hint.strip() if hint else "íŒíŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            self.hints[self.current_main].append(hint)  # DB ì €ì¥ X
            return hint
        except Exception as e:
            print(f"íŒíŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return "íŒíŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    async def generate_feedback(self, last_answer: str):
        try:
            prompt = PromptTemplate(template=self._get_feedback_template(), input_variables=['answer'])
            chain = LLMChain(prompt=prompt, llm=self.llm)
            # ë¹„ë™ê¸° í˜¸ì¶œì„ ë™ê¸° í˜¸ì¶œë¡œ ë³€ê²½
            feedback = chain.run({'answer': last_answer})
            feedback = feedback.strip() if feedback else "í”¼ë“œë°±ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

            self.feedbacks[self.current_main].append(feedback)  # DB ì €ì¥ X
            return feedback
        except Exception as e:
            print(f"í”¼ë“œë°± ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return "í”¼ë“œë°±ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    def _get_question_template(self):
        return f'''
        ë‹¤ìŒ ì´ë ¥ì„œì™€ ì±„ìš© ê³µê³ ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

        [ì´ë ¥ì„œ]
        {self.resume[:1000]}  # ì´ë ¥ì„œ í…ìŠ¤íŠ¸ë¥¼ 1000ìë¡œ ì œí•œ

        [ì±„ìš© ê³µê³ ]
        {self.recruit_url[:500]}  # ì±„ìš© ê³µê³  URLì„ 500ìë¡œ ì œí•œ

        [ì˜ˆì‹œ ì§ˆë¬¸]
        {self.example_questions}

        ìš”êµ¬ì‚¬í•­:
        1. í•œêµ­ì–´ë¡œ ì‘ì„±
        2. ì´ë ¥ì„œì™€ ì±„ìš© ê³µê³ ì— ë§ëŠ” êµ¬ì²´ì ì¸ ì§ˆë¬¸
        3. ì˜ˆì‹œ ì§ˆë¬¸ê³¼ ë¹„ìŠ·í•œ ìŠ¤íƒ€ì¼ë¡œ ì‘ì„±
        4. "ì§ˆë¬¸: ~" í˜•ì‹ìœ¼ë¡œ ì‘ì„±
        5. ì¶”ê°€ ì„¤ëª… ì—†ì´ ì§ˆë¬¸ë§Œ ì‘ì„±
        '''

    def _get_follow_up_template(self):
        return f'''
        You are an expert AI job interviewer.
        Use the following answer from a candidate to create a follow-up question in Korean:
        {{answer}}

        The follow-up question must:
        1. Be in Korean.
        2. Avoid repetition of previously generated questions.
        3. Focus on details mentioned in the answer.
        4. Explore the reasoning, challenges, results, or methodology in the answer.
        5. Only provide one follow-up question at a time.
        6. Always follow this format: "ì§ˆë¬¸: ~."
        '''

    def _get_hint_template(self):       # íŒíŠ¸ ìƒì„± í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        return f'''
        [Resume Context]
        {self.resume}

        [Current Question]
        {{question}}

        [Guidelines]
        1. ë‹µë³€ ì‹œ ê°•ì¡°í•´ì•¼ í•  ê¸°ìˆ  í‚¤ì›Œë“œ 3ê°œ ì¶”ì¶œ
        2. STAR(Situation-Task-Action-Result) ë°©ì‹ ì ìš© ì œì•ˆ
        3. êµ¬ì²´ì ì¸ ìˆ«ì/ìˆ˜ì¹˜ ì‚¬ìš© ê¶Œì¥
        4. 2ë¬¸ì¥ ì´ë‚´ë¡œ ìš”ì•½ëœ ì¡°ì–¸
        '''

    def _get_feedback_template(self):   # í”¼ë“œë°± ìƒì„± í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        return f'''
        [Evaluation Rubric]
        - ëª…í™•ì„±: 1~5ì 
        - ê´€ë ¨ì„±: 1~5ì  
        - êµ¬ì²´ì„±: 1~5ì 
        - ì „ë¬¸ì„±: 1~5ì 

        [Answer Analysis]
        {{answer}}

        [Feedback Requirements]
        1. ê° í‰ê°€ í•­ëª©ë³„ ì ìˆ˜ ë° ê·¼ê±°
        2. ê°œì„ ì„ ìœ„í•œ ì•¡ì…˜ ì•„ì´í…œ 3ê°œ
        3. ëª¨ë²” ë‹µì•ˆ ì˜ˆì‹œ í¬í•¨
        4. GPT-4 Turboì˜ 1750 í† í° ì œí•œ ë‚´ì—ì„œ ì™„ê²°ì„± ìˆëŠ” ì‘ë‹µ
        '''
