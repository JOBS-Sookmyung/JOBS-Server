import os
import pandas as pd
from PyPDF2 import PdfReader
import openai
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain_community.llms import OpenAI
from routers.pdf_storage import pdf_storage
from config import FILE_DIR, API_KEY
from db import SessionLocal, MainQuestionDB, FollowUpDB, InterviewSessionDB
from typing import Optional, Dict, Any

class InterviewSession:
    def __init__(self, token: str, question_num=5, answer_per_question=5, mock_data_path=None):
        self.token = token
        
        # PDF ë°ì´í„° ë¡œë“œ
        pdf_data = pdf_storage.get_pdf(token)
        if not pdf_data:
            print(f"âš ï¸ PDF ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {token}")
            # ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”
            self.resume = "ì´ë ¥ì„œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
            self.recruit_url = "ì±„ìš© ê³µê³  URLì´ ì—†ìŠµë‹ˆë‹¤."
        else:
            self.resume = pdf_data.get("resume_text", "ì´ë ¥ì„œ í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            self.recruit_url = pdf_data.get("recruitUrl", "ì±„ìš© ê³µê³  URLì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì„¸ì…˜ ì´ˆê¸°í™”
        self.current_main = 0
        self.current_follow_up = 0
        self.current_answer = 0
        self.question_num = question_num
        self.answer_per_question = answer_per_question
        self.main_questions = []
        self.follow_up_questions = [[] for _ in range(question_num)]
        self.answers = [[] for _ in range(question_num)]
        self.hints = [[] for _ in range(question_num)]
        self.feedbacks = [[] for _ in range(question_num)]
        
        self.mock_data_path = mock_data_path
        self.example_questions = self._load_mock_interview_data(mock_data_path)

    def _load_mock_interview_data(self, mock_data_path=None):
        """ëª¨ì˜ ë©´ì ‘ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” ë©”ì„œë“œ"""
        if not mock_data_path:
            mock_data_path = os.path.join(FILE_DIR, "mock_interview_data.json")
        
        try:
            # ğŸ”¥ ìˆ˜ì •ë¨: JSON íŒŒì¼ì´ ì—†ì„ ê²½ìš° ê¸°ë³¸ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ ì œê³µ
            if os.path.exists(mock_data_path):
                df = pd.read_json(mock_data_path)
                return "\n".join(df['question'].tolist()[:5])  # ìƒìœ„ 5ê°œ ì§ˆë¬¸ë§Œ ì‚¬ìš©
            else:
                return """
                í”„ë¡œì íŠ¸ì—ì„œ ê°€ì¥ í° ë„ì „ ê³¼ì œëŠ” ë¬´ì—‡ì´ì—ˆë‚˜ìš”?
                íŒ€ í”„ë¡œì íŠ¸ì—ì„œ ê°ˆë“±ì´ ë°œìƒí–ˆì„ ë•Œ ì–´ë–»ê²Œ í•´ê²°í•˜ì…¨ë‚˜ìš”?
                ê¸°ìˆ  ìŠ¤íƒì„ ì„ íƒí•œ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?
                í”„ë¡œì íŠ¸ì—ì„œ ë³¸ì¸ì˜ ì—­í• ì€ ë¬´ì—‡ì´ì—ˆë‚˜ìš”?
                ê°€ì¥ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œí•œ í”„ë¡œì íŠ¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?
                """
        except Exception as e:
            print(f"ëª¨ì˜ ë©´ì ‘ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {str(e)}")
            return ""

    #ëŒ€í‘œì§ˆë¬¸ ìƒì„±
    async def generate_main_questions(self, num_questions: int = 5):
        """ì—¬ëŸ¬ ê°œì˜ ëŒ€í‘œ ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ë©”ì„œë“œ"""
        try:
            questions = []
            print(f"ëŒ€í‘œ ì§ˆë¬¸ ìƒì„± ì‹œì‘ - ëª©í‘œ ê°œìˆ˜: {num_questions}")
            
            for i in range(num_questions):
                print(f"ğŸ“ {i+1}ë²ˆì§¸ ì§ˆë¬¸ ìƒì„± ì‹œë„ ì¤‘...")
                question = await self.generate_main_question()
                
                if question:
                    questions.append(question)
                    print(f"âœ… {i+1}ë²ˆì§¸ ì§ˆë¬¸ ìƒì„± ì„±ê³µ: {question}")
                else:
                    print(f"âŒ {i+1}ë²ˆì§¸ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨")
                    break
            
            if not questions:
                print("âŒ ìƒì„±ëœ ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                return ["ëŒ€í‘œì§ˆë¬¸ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."] * num_questions
            
            print(f"âœ… ì´ {len(questions)}ê°œì˜ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ")
            print(f"ìƒì„±ëœ ì§ˆë¬¸ ëª©ë¡: {questions}")
            return questions
            
        except Exception as e:
            print(f"âŒ ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return ["ëŒ€í‘œì§ˆë¬¸ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."] * num_questions

    async def generate_main_question(self):
        try:
            if len(self.main_questions) >= self.question_num:
                print("âŒ ìµœëŒ€ ì§ˆë¬¸ ìˆ˜ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.")
                return None
            
            print("ğŸ“ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")
            prompt = PromptTemplate(
                template=self._get_question_template(),
                input_variables=['resume', 'job_url']
            )
            chain = LLMChain(prompt=prompt, llm=self.llm)

            question = chain.run({
                'resume': self.resume,
                'job_url': self.recruit_url
            }).strip()
            
            if "ì§ˆë¬¸:" in question:
                question = question.split("ì§ˆë¬¸:")[1].strip()
            
            # ğŸ”¥ ìˆ˜ì •ë¨: ìƒì„±ëœ ì§ˆë¬¸ì„ DBì— ì €ì¥í•˜ë„ë¡ ë³€ê²½
            db = SessionLocal()
            try:
                session = db.query(InterviewSessionDB).filter_by(session_token=self.token).first()
                if not session:
                    print(f"âŒ ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.token}")
                    return None
                
                new_question = ChatMessageDB(
                    session_id=session.id,
                    message_type="main_question",  # ë©”ì¸ ì§ˆë¬¸ íƒ€ì… ì§€ì •
                    content=question
                )
                db.add(new_question)
                db.commit()
                db.refresh(new_question)
                
                self.main_questions.append(question)
                print(f"âœ… ì§ˆë¬¸ ìƒì„± ì„±ê³µ: {question}")
                
                return question
                    
            except Exception as db_error:
                print(f"âŒ DB ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(db_error)}")
                db.rollback()
            finally:
                db.close()
            
            return None
            
        except Exception as e:
            print(f"âŒ ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None

    # ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„±
    async def generate_follow_up(self, last_answer: str):
        try:
            if len(self.follow_up_questions[self.current_main]) >= self.answer_per_question - 1:
                return "ë” ì´ìƒì˜ ê¼¬ë¦¬ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤."
            
            prompt = PromptTemplate(template=self._get_follow_up_template(), input_variables=['answer'])
            chain = LLMChain(prompt=prompt, llm=self.llm)
            question = chain.run({'answer': last_answer})
            question = question.strip() if question else "ê¼¬ë¦¬ì§ˆë¬¸ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

            # DBì— ì €ì¥
            db = SessionLocal()
            try:
                # í˜„ì¬ ì„¸ì…˜ì˜ ë©”ì¸ ì§ˆë¬¸ì„ ê°€ì ¸ì˜´
                session = db.query(InterviewSessionDB).filter_by(session_token=self.token).first()
                if not session:
                    print(f"âŒ ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.token}")
                    return question
                
                # í˜„ì¬ ë©”ì¸ ì§ˆë¬¸ ì¸ë±ìŠ¤ì— í•´ë‹¹í•˜ëŠ” ì§ˆë¬¸ì„ ê°€ì ¸ì˜´
                main_questions = db.query(MainQuestionDB).filter_by(session_id=session.id).all()
                if not main_questions or self.current_main >= len(main_questions):
                    print(f"âŒ ë©”ì¸ ì§ˆë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ì¸ë±ìŠ¤ {self.current_main}")
                    return question
                
                main_question = main_questions[self.current_main]
                
                new_follow_up = FollowUpDB(
                    session_id=main_question.session_id,
                    main_question_id=main_question.id,
                    content=question
                )
                db.add(new_follow_up)
                db.commit()
                db.refresh(new_follow_up)
                
                # ë©”ëª¨ë¦¬ì—ë„ ì €ì¥
                self.follow_up_questions[self.current_main].append(question)
            finally:
                db.close()

            return question
        except Exception as e:
            print(f"ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return "ê¼¬ë¦¬ì§ˆë¬¸ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    def store_user_answer(self, session_id: int, answer: str):
        """ì‚¬ìš©ìì˜ ë‹µë³€ì„ ì €ì¥í•©ë‹ˆë‹¤."""
        try:
            # í˜„ì¬ ì§ˆë¬¸ ì¸ë±ìŠ¤ì— ë‹µë³€ ì €ì¥
            if 0 <= self.current_main < len(self.answers):
                self.answers[self.current_main].append(answer)
                print(f"âœ… ë‹µë³€ ì €ì¥ ì™„ë£Œ - ì§ˆë¬¸ {self.current_main + 1}")
            else:
                print(f"âš ï¸ ë‹µë³€ ì €ì¥ ì‹¤íŒ¨ - ìœ íš¨í•˜ì§€ ì•Šì€ ì§ˆë¬¸ ì¸ë±ìŠ¤: {self.current_main}")
        except Exception as e:
            print(f"âŒ ë‹µë³€ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            raise

    async def generate_hint(self, question, question_index):
        try:
            print(f"íŒíŠ¸ ìƒì„± ì‹œì‘ - ì§ˆë¬¸ ì¸ë±ìŠ¤: {question_index}, ì§ˆë¬¸: {question}")
            
            # ì´ë ¥ì„œ í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ
            resume_text = self.resume[:1000] if len(self.resume) > 1000 else self.resume
            
            prompt = PromptTemplate(
                template=self._get_hint_template(),
                input_variables=['resume', 'question', 'question_index']
            )
            chain = LLMChain(prompt=prompt, llm=self.llm)
            
            hint = chain.run({
                'resume': resume_text,
                'question': question,
                'question_index': question_index
            })
            
            if not hint:
                raise ValueError(f"ì§ˆë¬¸ {question_index}ì— ëŒ€í•œ íŒíŠ¸ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            hint = hint.strip()
            print(f"ìƒì„±ëœ íŒíŠ¸ (ì§ˆë¬¸ {question_index}): {hint}")
            
            # íŒíŠ¸ë¥¼ ì„¸ì…˜ì˜ íŒíŠ¸ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥
            if 0 <= question_index < len(self.hints):
                self.hints[question_index].append(hint)
            
            return hint
            
        except Exception as e:
            print(f"íŒíŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ì§ˆë¬¸ {question_index}): {str(e)}")
            return f"ì§ˆë¬¸ {question_index}ì— ëŒ€í•œ íŒíŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    async def generate_feedback(self, last_answer: str):
        try:
            prompt = PromptTemplate(template=self._get_feedback_template(), input_variables=['answer'])
            chain = LLMChain(prompt=prompt, llm=self.llm)
            feedback = chain.run({'answer': last_answer})
            feedback = feedback.strip() if feedback else "í”¼ë“œë°±ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

            self.feedbacks[self.current_main].append(feedback)
            return feedback
        except Exception as e:
            print(f"í”¼ë“œë°± ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return "í”¼ë“œë°±ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    def _get_question_template(self):
        return f'''
        ë‹¤ìŒ ì´ë ¥ì„œì™€ ì±„ìš© ê³µê³ ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

        [ì´ë ¥ì„œ]
        {self.resume[:1000]}  # ì´ë ¥ì„œ í…ìŠ¤íŠ¸ë¥¼ 1000ìë¡œ ì œí•œ

        [ì±„ìš© ê³µê³ ]
        {self.recruit_url[:500]}  # ì±„ìš© ê³µê³  URLì„ 500ìë¡œ ì œí•œ

        [ì˜ˆì‹œ ì§ˆë¬¸]
        {self.example_questions}

        ìš”êµ¬ì‚¬í•­:
        1. Be in Korean.
        2. Be specific and tailored to the resume.
        3. Be similar to the example questions.
        4. Write only the question, without additional explanations or comments.
        '''

    def _get_follow_up_template(self):
        return f'''
        You are an expert AI job interviewer.
        Use the following answer from a candidate to create a follow-up question in Korean:
        {{answer}}

        The follow-up question must:
        1. Be in Korean.
        2. You must avoid repetition of previously generated questions.
        3. Be specific and you must focus on details mentioned in the answer.
        4. Explore the reasoning, challenges, results, or methodology in the answer.
        5. Be realistic and appropriate for a job interview setting.
        6. Only provide one follow-up question at a time.
        7. Provide only the follow-up question, without any additional explanations or comments.
        '''

    def _get_hint_template(self):       # íŒíŠ¸ ìƒì„± í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        return f'''
        [Resume Context]
        {self.resume}

        [Current Question]
        {{question}}

        [Guidelines]
        1. Extract three key technical keywords to emphasize in the response.  
        2. Suggest applying the STAR (Situation-Task-Action-Result) method.  
        3. Recommend using specific numbers/data.  
        4. Provide advice summarized in no more than two sentences.
        5. Be in Korean.
        6. Be specific and tailored to the resume.
        7. Only one question at a time.
        '''

    def _get_feedback_template(self):   # í”¼ë“œë°± ìƒì„± í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        return f'''
        The feedback must:
        1. Compliment specific strengths in the answer.
        2. Identify areas where the answer could be more specific or detailed.
        3. Provide concrete examples or suggestions for improvement directly related to the details mentioned in the answer.
        4. Be realistic and appropriate for a professional job interview setting.
        5. Be written in Korean, formatted with clear and professional language.
        6. Always include encouraging comments and actionable advice with a kind and supportive tone.
        7. A complete response within the 1,750-token limit of GPT-4 Turbo.
        
        Example Feedback:
        "ìš°ì„ , íŒ€ì›ë“¤ì˜ ì¥ì ê³¼ ê´€ì‹¬ì‚¬ë¥¼ íŒŒì•…í•˜ê¸° ìœ„í•´ ë³¸ì¸ì´ í•œ ë…¸ë ¥ì˜ ë‹¨ê³„ì™€ ê³¼ì •ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•˜ì‹  ë¶€ë¶„ì€ í›Œë¥­í•©ë‹ˆë‹¤! ë‹¤ë§Œ êµ¬ì²´ì ì¸ ê²½í—˜, ì˜ˆë¥¼ ë“¤ì–´ 'ì• ë‹ˆë¥¼ ì¢‹ì•„í•˜ëŠ” ì¹œêµ¬ì™€ì˜ ë¼í¬ë¥¼ í˜•ì„±í•˜ê¸° ìœ„í•´ ìš”ì¦˜ ìœ í–‰í•˜ëŠ” ë„·í”Œë¦­ìŠ¤ ì• ë‹ˆë©”ì´ì…˜ ì´ë¦„ì„ ì–¸ê¸‰í•˜ë©° ê°€ê¹Œì›Œì§ˆ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤'ì™€ ê°™ì€ êµ¬ì²´ì ì¸ ì˜ˆì‹œê°€ ë¶€ì¡±í•´ ë³´ì…ë‹ˆë‹¤. ë‹¤ìŒì—ëŠ” ì´ëŸ° ë¶€ë¶„ì„ ì–¸ê¸‰í•˜ë©´ì„œ ë‹µë³€í•˜ë©´ ë”ìš±ë” ì‹ ë¢°ê°ì„ ì¤„ ìˆ˜ ìˆì–´ ì¢‹ì„ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤! ğŸ‘"
        
        When giving examples or suggestions, tailor them to the candidate's answer to make them relevant and specific. Avoid reusing generic or unrelated examples.
        Provide the feedback only, without additional explanations or comments in Korean.
        '''

     