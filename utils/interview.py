import os
import pandas as pd
from PyPDF2 import PdfReader
import openai
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain_community.llms import OpenAI
from routers.pdf_storage import pdf_storage
from config import FILE_DIR, API_KEY
from db import SessionLocal, MainQuestionDB, FollowUpDB  # DB ëª¨ë¸ ì„í¬íŠ¸

class InterviewSession:
    def __init__(self, token: str, question_num=5, answer_per_question=5, mock_data_path=None):
        self.token = token
        self.current_main = 0
        self.current_follow_up = 0
        self.current_answer = 0

        self.question_num = question_num
        self.answer_per_question = answer_per_question
        self.main_questions = []
        self.follow_up_questions = [[] for _ in range(question_num)]
        self.answers = [[] for _ in range(question_num)]
        self.hints = [[] for _ in range(question_num)]  # ì„¸ì…˜ ë‚´ ìœ ì§€ (DB ì €ì¥ X)
        self.feedbacks = [[] for _ in range(question_num)]  # ì„¸ì…˜ ë‚´ ìœ ì§€ (DB ì €ì¥ X)

        self.llm = OpenAI(api_key=API_KEY)

        # âœ… PDF í…ìŠ¤íŠ¸ & ì±„ìš© URL ì§ì ‘ ê°€ì ¸ì˜¤ê¸° (íŒŒì¼ ë³€í™˜ X)
        pdf_data = pdf_storage.get_pdf(token)
        if not pdf_data:
            raise ValueError(f"ğŸš¨ í•´ë‹¹ í† í°({token})ì— ëŒ€í•œ PDF íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        self.resume = pdf_data.get("resume_text", "ğŸš¨ ì´ë ¥ì„œ í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        self.recruit_url = pdf_data.get("recruitUrl", "ğŸš¨ ì±„ìš© ê³µê³  URLì´ ì—†ìŠµë‹ˆë‹¤.")

        self.mock_data_path = mock_data_path
        self.example_questions = self._load_mock_interview_data(mock_data_path)

    def get_current_state(self):
        return {
            "total_main": len(self.main_questions),
            "current_main": self.current_main,
            "current_follow_up": self.current_follow_up,
            "current_answer": self.current_answer,
            "remaining_answer": self.answer_per_question - self.current_answer,
        }

    def _load_mock_interview_data(self, mock_data_path=None):
        """ëª¨ì˜ ë©´ì ‘ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” ë©”ì„œë“œ"""
        if not mock_data_path:
            mock_data_path = os.path.join(FILE_DIR, "mock_interview_data.json")
        
        try:
            if os.path.exists(mock_data_path):
                df = pd.read_json(mock_data_path)
                return "\n".join(df['question'].tolist()[:5])  # ìƒìœ„ 5ê°œ ì§ˆë¬¸ë§Œ ì‚¬ìš©
            else:
                return """
                í”„ë¡œì íŠ¸ì—ì„œ ê°€ì¥ í° ë„ì „ ê³¼ì œëŠ” ë¬´ì—‡ì´ì—ˆë‚˜ìš”?
                íŒ€ í”„ë¡œì íŠ¸ì—ì„œ ê°ˆë“±ì´ ë°œìƒí–ˆì„ ë•Œ ì–´ë–»ê²Œ í•´ê²°í•˜ì…¨ë‚˜ìš”?
                ê¸°ìˆ  ìŠ¤íƒì„ ì„ íƒí•œ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?
                í”„ë¡œì íŠ¸ì—ì„œ ë³¸ì¸ì˜ ì—­í• ì€ ë¬´ì—‡ì´ì—ˆë‚˜ìš”?
                ê°€ì¥ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œí•œ í”„ë¡œì íŠ¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?
                """
        except Exception as e:
            print(f"ëª¨ì˜ ë©´ì ‘ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {str(e)}")
            return ""

    async def generate_main_questions(self, num_questions: int = 5):
        """ì—¬ëŸ¬ ê°œì˜ ëŒ€í‘œ ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ë©”ì„œë“œ"""
        try:
            questions = []
            for _ in range(num_questions):
                question = await self.generate_main_question()
                if question:
                    questions.append(question)
            return questions
        except Exception as e:
            print(f"ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return []

    async def generate_main_question(self):
        try:
            if len(self.main_questions) >= self.question_num:
                return None
            
            prompt = PromptTemplate(
                template=self._get_question_template(),
                input_variables=['resume', 'job_url']
            )
            chain = LLMChain(prompt=prompt, llm=self.llm)

            # ë¹„ë™ê¸° í˜¸ì¶œì„ ë™ê¸° í˜¸ì¶œë¡œ ë³€ê²½
            question = chain.run({
                'resume': self.resume,
                'job_url': self.recruit_url
            })
            
            # ì§ˆë¬¸ í˜•ì‹ ê²€ì¦ ë° ì •ì œ
            if not question or "ì§ˆë¬¸:" not in question:
                print(f"ì˜ëª»ëœ ì§ˆë¬¸ í˜•ì‹: {question}")
                return "ëŒ€í‘œì§ˆë¬¸ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                
            question = question.strip()
            if not question:
                return "ëŒ€í‘œì§ˆë¬¸ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

            # DBì— ì €ì¥
            db = SessionLocal()
            try:
                new_question = MainQuestionDB(session_id=self.token, content=question)
                db.add(new_question)
                db.commit()
                db.refresh(new_question)
                self.main_questions.append(question)
            except Exception as db_error:
                print(f"DB ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(db_error)}")
                db.rollback()
            finally:
                db.close()

            return question
        except Exception as e:
            print(f"ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return "ëŒ€í‘œì§ˆë¬¸ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    async def generate_follow_up(self, last_answer: str):
        try:
            if len(self.follow_up_questions[self.current_main]) >= self.answer_per_question - 1:
                return None
            
            prompt = PromptTemplate(template=self._get_follow_up_template(), input_variables=['answer'])
            chain = LLMChain(prompt=prompt, llm=self.llm)

            # ë¹„ë™ê¸° í˜¸ì¶œì„ ë™ê¸° í˜¸ì¶œë¡œ ë³€ê²½
            question = chain.run({'answer': last_answer})
            question = question.strip() if question else "ê¼¬ë¦¬ì§ˆë¬¸ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

            # **DBì— ì €ì¥**
            db = SessionLocal()
            try:
                new_follow_up = FollowUpDB(main_question_id=self.current_main, content=question)
                db.add(new_follow_up)
                db.commit()
                db.refresh(new_follow_up)
                self.follow_up_questions[self.current_main].append(question)
            finally:
                db.close()

            return question
        except Exception as e:
            print(f"ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return "ê¼¬ë¦¬ì§ˆë¬¸ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    def store_user_answer(self, question_id: int, answer: str):
        """ì‚¬ìš©ìì˜ ë‹µë³€ì„ DBì— ì €ì¥"""
        db = SessionLocal()
        try:
            follow_up = db.query(FollowUpDB).filter(FollowUpDB.id == question_id).first()
            if follow_up:
                follow_up.answer = answer
                db.commit()
                db.refresh(follow_up)
                self.answers[self.current_main].append(answer)
        finally:
            db.close()

    async def generate_hint(self, last_question):
        try:
            prompt = PromptTemplate(template=self._get_hint_template(), input_variables=['question'])
            chain = LLMChain(prompt=prompt, llm=self.llm)
            # ë¹„ë™ê¸° í˜¸ì¶œì„ ë™ê¸° í˜¸ì¶œë¡œ ë³€ê²½
            hint = chain.run({'question': last_question})
            hint = hint.strip() if hint else "íŒíŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            self.hints[self.current_main].append(hint)  # DB ì €ì¥ X
            return hint
        except Exception as e:
            print(f"íŒíŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return "íŒíŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    async def generate_feedback(self, last_answer: str):
        try:
            prompt = PromptTemplate(template=self._get_feedback_template(), input_variables=['answer'])
            chain = LLMChain(prompt=prompt, llm=self.llm)
            # ë¹„ë™ê¸° í˜¸ì¶œì„ ë™ê¸° í˜¸ì¶œë¡œ ë³€ê²½
            feedback = chain.run({'answer': last_answer})
            feedback = feedback.strip() if feedback else "í”¼ë“œë°±ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

            self.feedbacks[self.current_main].append(feedback)  # DB ì €ì¥ X
            return feedback
        except Exception as e:
            print(f"í”¼ë“œë°± ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return "í”¼ë“œë°±ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    def _get_question_template(self):
        return f'''
        You are an expert AI interviewer.
        Use the following resume and job description to make a question in Korean:

        [Resume]
        {self.resume}

        [Job Description]
        {self.recruit_url}

        Here are example questions from a mock interview dataset:
        {self.example_questions}

        The question must:
        1. Be in Korean.
        2. Be specific and tailored to the details of the resume & job description.
        3. Focus on the skills, experiences, or projects mentioned.
        4. Avoid repetition of previously generated questions.
        5. Be similar in style and detail to the examples provided.
        6. Only provide one question at a time.
        7. Be realistic and appropriate for a job interview setting.
        8. ADo not include any additional text or explanations.
        '''

    def _get_follow_up_template(self):
        return f'''
        You are an expert AI job interviewer.
        Use the following answer from a candidate to create a follow-up question in Korean:
        {{answer}}

        The follow-up question must:
        1. Be in Korean.
        2. Avoid repetition of previously generated questions.
        3. Focus on details mentioned in the answer.
        4. Explore the reasoning, challenges, results, or methodology in the answer.
        5. Only provide one follow-up question at a time.
        '''

    def _get_hint_template(self):       # íŒíŠ¸ ìƒì„± í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        return f'''
        [Resume Context]
        {self.resume}

        [Current Question]
        {{question}}

        [Guidelines]
        1. ë‹µë³€ ì‹œ ê°•ì¡°í•´ì•¼ í•  ê¸°ìˆ  í‚¤ì›Œë“œ 3ê°œ ì¶”ì¶œ
        2. STAR(Situation-Task-Action-Result) ë°©ì‹ ì ìš© ì œì•ˆ
        3. êµ¬ì²´ì ì¸ ìˆ«ì/ìˆ˜ì¹˜ ì‚¬ìš© ê¶Œì¥
        4. 2ë¬¸ì¥ ì´ë‚´ë¡œ ìš”ì•½ëœ ì¡°ì–¸
        '''

    def _get_feedback_template(self):   # í”¼ë“œë°± ìƒì„± í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        return f'''
        [Evaluation Rubric]
        - ëª…í™•ì„±: 1~5ì 
        - ê´€ë ¨ì„±: 1~5ì  
        - êµ¬ì²´ì„±: 1~5ì 
        - ì „ë¬¸ì„±: 1~5ì 

        [Answer Analysis]
        {{answer}}

        [Feedback Requirements]
        1. ê° í‰ê°€ í•­ëª©ë³„ ì ìˆ˜ ë° ê·¼ê±°
        2. ê°œì„ ì„ ìœ„í•œ ì•¡ì…˜ ì•„ì´í…œ 3ê°œ
        3. ëª¨ë²” ë‹µì•ˆ ì˜ˆì‹œ í¬í•¨
        4. GPT-4 Turboì˜ 1750 í† í° ì œí•œ ë‚´ì—ì„œ ì™„ê²°ì„± ìˆëŠ” ì‘ë‹µ
        '''
