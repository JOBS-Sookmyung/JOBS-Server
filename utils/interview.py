import os
import pandas as pd
from PyPDF2 import PdfReader
import openai
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain_community.llms import OpenAI
from routers.pdf_storage import pdf_storage
from config import FILE_DIR, API_KEY
from db import SessionLocal, MainQuestionDB, FollowUpDB, InterviewSessionDB
from typing import Optional, Dict, Any

class InterviewSession:
    def __init__(self, token: str, question_num=5, answer_per_question=5, mock_data_path=None):
        self.token = token
        
        # PDF ë°ì´í„° ë¡œë“œ
        pdf_data = pdf_storage.get_pdf(token)
        if not pdf_data:
            print(f"âš ï¸ PDF ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {token}")
            # ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”
            self.resume = "ì´ë ¥ì„œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
            self.recruit_url = "ì±„ìš© ê³µê³  URLì´ ì—†ìŠµë‹ˆë‹¤."
        else:
            self.resume = pdf_data.get("resume_text", "ì´ë ¥ì„œ í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            self.recruit_url = pdf_data.get("recruitUrl", "ì±„ìš© ê³µê³  URLì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì„¸ì…˜ ì´ˆê¸°í™”
        self.current_main = 0
        self.current_follow_up = 0
        self.current_answer = 0
        self.question_num = question_num
        self.answer_per_question = answer_per_question
        self.main_questions = []
        self.follow_up_questions = [[] for _ in range(question_num)]
        self.answers = [[] for _ in range(question_num)]
        self.hints = [[] for _ in range(question_num)]
        self.feedbacks = [[] for _ in range(question_num)]
        
        self.mock_data_path = mock_data_path
        self.example_questions = self._load_mock_interview_data(mock_data_path)
        
        print(f"ìƒˆë¡œìš´ ì„¸ì…˜ ìƒì„± ì™„ë£Œ: {token}")
        
        self.llm = OpenAI(api_key=API_KEY)

    def get_current_state(self):
        return {
            "total_main": len(self.main_questions),
            "current_main": self.current_main,
            "current_follow_up": self.current_follow_up,
            "current_answer": self.current_answer,
            "remaining_answer": self.answer_per_question - self.current_answer,
        }

    def _load_mock_interview_data(self, mock_data_path=None):
        """ëª¨ì˜ ë©´ì ‘ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” ë©”ì„œë“œ"""
        if not mock_data_path:
            mock_data_path = os.path.join(FILE_DIR, "mock_interview_data.json")
        
        try:
            if os.path.exists(mock_data_path):
                df = pd.read_json(mock_data_path)
                return "\n".join(df['question'].tolist()[:5])  # ìƒìœ„ 5ê°œ ì§ˆë¬¸ë§Œ ì‚¬ìš©
            else:
                return """
                í”„ë¡œì íŠ¸ì—ì„œ ê°€ì¥ í° ë„ì „ ê³¼ì œëŠ” ë¬´ì—‡ì´ì—ˆë‚˜ìš”?
                íŒ€ í”„ë¡œì íŠ¸ì—ì„œ ê°ˆë“±ì´ ë°œìƒí–ˆì„ ë•Œ ì–´ë–»ê²Œ í•´ê²°í•˜ì…¨ë‚˜ìš”?
                ê¸°ìˆ  ìŠ¤íƒì„ ì„ íƒí•œ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?
                í”„ë¡œì íŠ¸ì—ì„œ ë³¸ì¸ì˜ ì—­í• ì€ ë¬´ì—‡ì´ì—ˆë‚˜ìš”?
                ê°€ì¥ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œí•œ í”„ë¡œì íŠ¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?
                """
        except Exception as e:
            print(f"ëª¨ì˜ ë©´ì ‘ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {str(e)}")
            return ""

    #ëŒ€í‘œì§ˆë¬¸ ìƒì„±
    async def generate_main_questions(self, num_questions: int = 5):
        """ì—¬ëŸ¬ ê°œì˜ ëŒ€í‘œ ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ë©”ì„œë“œ"""
        try:
            questions = []
            print(f"ëŒ€í‘œ ì§ˆë¬¸ ìƒì„± ì‹œì‘ - ëª©í‘œ ê°œìˆ˜: {num_questions}")
            
            for i in range(num_questions):
                print(f"ğŸ“ {i+1}ë²ˆì§¸ ì§ˆë¬¸ ìƒì„± ì‹œë„ ì¤‘...")
                question = await self.generate_main_question()
                
                if question:
                    questions.append(question)
                    print(f"âœ… {i+1}ë²ˆì§¸ ì§ˆë¬¸ ìƒì„± ì„±ê³µ: {question}")
                else:
                    print(f"âŒ {i+1}ë²ˆì§¸ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨")
                    break
            
            if not questions:
                print("âŒ ìƒì„±ëœ ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                return ["ëŒ€í‘œì§ˆë¬¸ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."] * num_questions
            
            print(f"âœ… ì´ {len(questions)}ê°œì˜ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ")
            print(f"ìƒì„±ëœ ì§ˆë¬¸ ëª©ë¡: {questions}")
            return questions
            
        except Exception as e:
            print(f"âŒ ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return ["ëŒ€í‘œì§ˆë¬¸ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."] * num_questions

    async def generate_main_question(self):
        try:
            if len(self.main_questions) >= self.question_num:
                print("âŒ ìµœëŒ€ ì§ˆë¬¸ ìˆ˜ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.")
                return None
            
            print("ğŸ“ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")
            prompt = PromptTemplate(
                template=self._get_question_template(),
                input_variables=['resume', 'job_url']
            )
            chain = LLMChain(prompt=prompt, llm=self.llm)

            # ìµœëŒ€ 3ë²ˆê¹Œì§€ ì‹œë„
            max_attempts = 3
            for attempt in range(max_attempts):
                print(f"ğŸ¤– OpenAI API í˜¸ì¶œ ì¤‘... (ì‹œë„ {attempt + 1}/{max_attempts})")
                question = chain.run({
                    'resume': self.resume,
                    'job_url': self.recruit_url
                })
                print(f"ğŸ“„ API ì‘ë‹µ: {question}")
                
                # ì§ˆë¬¸ í˜•ì‹ ê²€ì¦ ë° ì •ì œ
                if not question:
                    print("âŒ ì§ˆë¬¸ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    continue
                
                # "ì§ˆë¬¸:" ë¶€ë¶„ ì œê±°í•˜ê³  ì‹¤ì œ ì§ˆë¬¸ë§Œ ì¶”ì¶œ
                question = question.strip()
                if "ì§ˆë¬¸:" in question:
                    question = question.split("ì§ˆë¬¸:")[1].strip()
                    print(f"âœ… ì§ˆë¬¸ ì¶”ì¶œ ì™„ë£Œ: {question}")
                else:
                    print("âš ï¸ 'ì§ˆë¬¸:' í˜•ì‹ì´ ì—†ìŠµë‹ˆë‹¤.")
                    continue
                
                if not question:
                    print("âŒ ì§ˆë¬¸ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                    continue

                # ì¤‘ë³µ ì²´í¬
                is_duplicate = False
                for existing_question in self.main_questions:
                    # ìœ ì‚¬ë„ ì²´í¬ (ë‹¨ìˆœ ë¬¸ìì—´ í¬í•¨ ì—¬ë¶€)
                    if question in existing_question or existing_question in question:
                        print(f"âš ï¸ ì¤‘ë³µëœ ì§ˆë¬¸ ê°ì§€: {question}")
                        is_duplicate = True
                        break
                
                if is_duplicate:
                    continue

                # DBì— ì €ì¥
                print("ğŸ’¾ DB ì €ì¥ ì‹œë„ ì¤‘...")
                db = SessionLocal()
                try:
                    # ì„¸ì…˜ IDë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ InterviewSessionDB ì¡°íšŒ
                    session = db.query(InterviewSessionDB).filter_by(session_token=self.token).first()
                    if not session:
                        print(f"âŒ ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.token}")
                        continue
                    
                    new_question = MainQuestionDB(
                        session_id=session.id,  # ì„¸ì…˜ ID ì‚¬ìš©
                        content=question
                    )
                    db.add(new_question)
                    db.commit()
                    db.refresh(new_question)
                    
                    # ë©”ëª¨ë¦¬ì— ì§ˆë¬¸ ì¶”ê°€
                    self.main_questions.append(question)
                    print(f"âœ… ì§ˆë¬¸ ìƒì„± ì„±ê³µ: {question}")
                    
                    return question
                    
                except Exception as db_error:
                    print(f"âŒ DB ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(db_error)}")
                    db.rollback()
                    continue
                finally:
                    db.close()
            
            print("âŒ ìœ íš¨í•œ ì§ˆë¬¸ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return None
            
        except Exception as e:
            print(f"âŒ ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None

    # ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„±
    async def generate_follow_up(self, last_answer: str):
        try:
            if len(self.follow_up_questions[self.current_main]) >= self.answer_per_question - 1:
                return "ë” ì´ìƒì˜ ê¼¬ë¦¬ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤."
            
            prompt = PromptTemplate(template=self._get_follow_up_template(), input_variables=['answer'])
            chain = LLMChain(prompt=prompt, llm=self.llm)
            question = chain.run({'answer': last_answer})
            question = question.strip() if question else "ê¼¬ë¦¬ì§ˆë¬¸ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

            # DBì— ì €ì¥
            db = SessionLocal()
            try:
                # í˜„ì¬ ì„¸ì…˜ì˜ ë©”ì¸ ì§ˆë¬¸ì„ ê°€ì ¸ì˜´
                session = db.query(InterviewSessionDB).filter_by(session_token=self.token).first()
                if not session:
                    print(f"âŒ ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.token}")
                    return question
                
                # í˜„ì¬ ë©”ì¸ ì§ˆë¬¸ ì¸ë±ìŠ¤ì— í•´ë‹¹í•˜ëŠ” ì§ˆë¬¸ì„ ê°€ì ¸ì˜´
                main_questions = db.query(MainQuestionDB).filter_by(session_id=session.id).all()
                if not main_questions or self.current_main >= len(main_questions):
                    print(f"âŒ ë©”ì¸ ì§ˆë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ì¸ë±ìŠ¤ {self.current_main}")
                    return question
                
                main_question = main_questions[self.current_main]
                
                new_follow_up = FollowUpDB(
                    session_id=main_question.session_id,
                    main_question_id=main_question.id,
                    content=question
                )
                db.add(new_follow_up)
                db.commit()
                db.refresh(new_follow_up)
                
                # ë©”ëª¨ë¦¬ì—ë„ ì €ì¥
                self.follow_up_questions[self.current_main].append(question)
                return question
                
            except Exception as e:
                print(f"âŒ DB ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                db.rollback()
                return question
            finally:
                db.close()

        except Exception as e:
            print(f"ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return "ê¼¬ë¦¬ì§ˆë¬¸ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    def store_user_answer(self, session_id: int, answer: str):
        """ì‚¬ìš©ìì˜ ë‹µë³€ì„ ì €ì¥í•©ë‹ˆë‹¤."""
        try:
            # í˜„ì¬ ì§ˆë¬¸ ì¸ë±ìŠ¤ì— ë‹µë³€ ì €ì¥
            if 0 <= self.current_main < len(self.answers):
                self.answers[self.current_main].append(answer)
                print(f"âœ… ë‹µë³€ ì €ì¥ ì™„ë£Œ - ì§ˆë¬¸ {self.current_main + 1}")
            else:
                print(f"âš ï¸ ë‹µë³€ ì €ì¥ ì‹¤íŒ¨ - ìœ íš¨í•˜ì§€ ì•Šì€ ì§ˆë¬¸ ì¸ë±ìŠ¤: {self.current_main}")
        except Exception as e:
            print(f"âŒ ë‹µë³€ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            raise

    async def generate_hint(self, question, question_index):
        try:
            print(f"íŒíŠ¸ ìƒì„± ì‹œì‘ - ì§ˆë¬¸ ì¸ë±ìŠ¤: {question_index}, ì§ˆë¬¸: {question}")
            
            # ì´ë ¥ì„œ í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ
            resume_text = self.resume[:1000] if len(self.resume) > 1000 else self.resume
            
            prompt = PromptTemplate(
                template=self._get_hint_template(),
                input_variables=['resume', 'question', 'question_index']
            )
            chain = LLMChain(prompt=prompt, llm=self.llm)
            
            hint = chain.run({
                'resume': resume_text,
                'question': question,
                'question_index': question_index
            })
            
            if not hint:
                raise ValueError(f"ì§ˆë¬¸ {question_index}ì— ëŒ€í•œ íŒíŠ¸ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            hint = hint.strip()
            print(f"ìƒì„±ëœ íŒíŠ¸ (ì§ˆë¬¸ {question_index}): {hint}")
            
            # íŒíŠ¸ë¥¼ ì„¸ì…˜ì˜ íŒíŠ¸ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥
            if 0 <= question_index < len(self.hints):
                self.hints[question_index].append(hint)
            
            return hint
            
        except Exception as e:
            print(f"íŒíŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ì§ˆë¬¸ {question_index}): {str(e)}")
            return f"ì§ˆë¬¸ {question_index}ì— ëŒ€í•œ íŒíŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    async def generate_feedback(self, last_answer: str):
        try:
            prompt = PromptTemplate(template=self._get_feedback_template(), input_variables=['answer'])
            chain = LLMChain(prompt=prompt, llm=self.llm)
            feedback = chain.run({'answer': last_answer})
            feedback = feedback.strip() if feedback else "í”¼ë“œë°±ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

            self.feedbacks[self.current_main].append(feedback)
            return feedback
        except Exception as e:
            print(f"í”¼ë“œë°± ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return "í”¼ë“œë°±ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    def _get_question_template(self):
        return f'''
        ë‹¤ìŒ ì´ë ¥ì„œì™€ ì±„ìš© ê³µê³ ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

        [ì´ë ¥ì„œ]
        {self.resume[:1000]}  # ì´ë ¥ì„œ í…ìŠ¤íŠ¸ë¥¼ 1000ìë¡œ ì œí•œ

        [ì±„ìš© ê³µê³ ]
        {self.recruit_url[:500]}  # ì±„ìš© ê³µê³  URLì„ 500ìë¡œ ì œí•œ

        [ì˜ˆì‹œ ì§ˆë¬¸]
        {self.example_questions}

        ìš”êµ¬ì‚¬í•­:
        1. í•œêµ­ì–´ë¡œ ì‘ì„±
        2. ì´ë ¥ì„œì™€ ì±„ìš© ê³µê³ ì— ë§ëŠ” êµ¬ì²´ì ì¸ ì§ˆë¬¸
        3. ì˜ˆì‹œ ì§ˆë¬¸ê³¼ ë¹„ìŠ·í•œ ìŠ¤íƒ€ì¼ë¡œ ì‘ì„±
        4. "ì§ˆë¬¸: ~" í˜•ì‹ìœ¼ë¡œ ì‘ì„±
        5. ì¶”ê°€ ì„¤ëª… ì—†ì´ ì§ˆë¬¸ë§Œ ì‘ì„±
        '''

    def _get_follow_up_template(self):
        return f'''
        You are an expert AI job interviewer.
        Use the following answer from a candidate to create a follow-up question in Korean:
        {{answer}}

        The follow-up question must:
        1. Be in Korean.
        2. You must avoid repetition of previously generated questions.
        3. Be specific and you must focus on details mentioned in the answer.
        4. Explore the reasoning, challenges, results, or methodology in the answer.
        5. Be realistic and appropriate for a job interview setting.
        6. Only provide one follow-up question at a time.
        7. Provide only the follow-up question, without any additional explanations or comments.
        '''

    def _get_hint_template(self):
        return '''
        ë‹¤ìŒ ì´ë ¥ì„œì™€ ë©´ì ‘ ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ íŒíŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

        [ì´ë ¥ì„œ]
        {resume}

        [ë©´ì ‘ ì§ˆë¬¸ {question_index}]
        {question}

        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ íŒíŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:
        1. í•µì‹¬ í‚¤ì›Œë“œ: (ë‹µë³€ì— ê¼­ í¬í•¨ë˜ì–´ì•¼ í•  3-4ê°œì˜ í‚¤ì›Œë“œ)
        2. STAR ê¸°ë²• ì ìš© ë°©í–¥:
           - Situation: (ìƒí™© ì„¤ëª… ë°©í–¥)
           - Task: (ê³¼ì œ/ëª©í‘œ ì„¤ëª… ë°©í–¥)
           - Action: (í–‰ë™ ì„¤ëª… ë°©í–¥)
           - Result: (ê²°ê³¼ ì„¤ëª… ë°©í–¥)
        3. êµ¬ì²´ì ì¸ ìˆ˜ì¹˜/ë°ì´í„° ì œì•ˆ: (ê°€ëŠ¥í•œ ê²½ìš°)
        4. ì°¨ë³„í™” í¬ì¸íŠ¸: (ë‹¤ë¥¸ ì§€ì›ìì™€ ì°¨ë³„í™”í•  ìˆ˜ ìˆëŠ” ë‹µë³€ ë°©í–¥)
        '''

    def _get_feedback_template(self):   # í”¼ë“œë°± ìƒì„± í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        return f'''
        [Evaluation Rubric]
        - ëª…í™•ì„±: 1~5ì 
        - ê´€ë ¨ì„±: 1~5ì  
        - êµ¬ì²´ì„±: 1~5ì 
        - ì „ë¬¸ì„±: 1~5ì 

        [Answer Analysis]
        {{answer}}

        [Feedback Requirements]
        1. ê° í‰ê°€ í•­ëª©ë³„ ì ìˆ˜ ë° ê·¼ê±°
        2. ê°œì„ ì„ ìœ„í•œ ì•¡ì…˜ ì•„ì´í…œ 3ê°œ
        3. ëª¨ë²” ë‹µì•ˆ ì˜ˆì‹œ í¬í•¨
        4. GPT-4 Turboì˜ 1750 í† í° ì œí•œ ë‚´ì—ì„œ ì™„ê²°ì„± ìˆëŠ” ì‘ë‹µ
        '''
